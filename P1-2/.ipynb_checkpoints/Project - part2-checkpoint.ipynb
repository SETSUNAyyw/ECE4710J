{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686361fc",
   "metadata": {},
   "source": [
    "# Project Part II: Predicting Housing Prices - Build Your Own Model\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed53d17",
   "metadata": {},
   "source": [
    "### Grading Scheme\n",
    "\n",
    "Your grade for the project will be based on your training RMSE and test RMSE. The thresholds are as follows:\n",
    "\n",
    "Points | 9 | 7 | 5 | 3\n",
    "--- | --- | --- | --- | ---\n",
    "Training RMSE | Less than 60k | [60k, 120k) | [120k, 200k) | More than 230k\n",
    "\n",
    "Points | 9 | 7 | 5 | 3\n",
    "--- | --- | --- | --- | ---\n",
    "Test RMSE | Less than 65k | [65k, 130k) | [130k, 230k) | More than 230k\n",
    "\n",
    "The top 20% of the submissions with the least testing errors will receive the additional two points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08e008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Imports You Might Need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Extract Dataset\n",
    "with zipfile.ZipFile('cook_county_contest_data.zip') as item:\n",
    "    item.extractall()\n",
    "    \n",
    "    \n",
    "### Note: we filtered the data in cook_county_contest_data, \n",
    "####so please use this dataset instead of the old one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4be2e9",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "This notebook is specifically designed to guide you through the process of exporting your model's predictions on the test dataset for submission so you can see how your model performs.\n",
    "\n",
    "Most of what you have done in project part I should be transferrable here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f09b63",
   "metadata": {},
   "source": [
    "## Step 1. Set up all the helper functions for your `process_data_fm` function.\n",
    "\n",
    "**Copy-paste all of the helper functions your `process_data_fm` need here in the following cell**. You **do not** have to fill out all of the functions in the cell below -- only fill out those that are actually useful to your feature engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "df894371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_bedrooms(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing at least the Description column.\n",
    "    \"\"\"\n",
    "    with_rooms = data.copy()\n",
    "    with_rooms[\"Bedrooms\"] = with_rooms[\"Description\"].str.findall(\".*(\\d+) of which are bedrooms.*\").str[0].astype(int)\n",
    "    with_rooms[\"Rooms\"] = with_rooms[\"Description\"].str.findall(\".*(\\d+) rooms.*\").str[0].astype(int)\n",
    "    with_rooms[\"Bathrooms\"] = with_rooms[\"Description\"].str.findall(\".*(\\d+) of which are bathrooms.*\").str[0].astype(int)\n",
    "    return with_rooms\n",
    "#     return with_rooms\n",
    "\n",
    "def ohe_model_group(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material.  New columns are of the form 0x_QUALITY.\n",
    "    \"\"\"\n",
    "    oh_enc = OneHotEncoder()\n",
    "    oh_enc.fit(data[[\"Modeling Group\"]])\n",
    "    ohe_cols = pd.DataFrame(oh_enc.transform(data[[\"Modeling Group\"]]).todense(), \n",
    "                           columns = oh_enc.get_feature_names(),\n",
    "                           index = data.index)\n",
    "    return data.join(ohe_cols)\n",
    "def ohe_roof_material(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material.  New columns are of the form 0x_QUALITY.\n",
    "    \"\"\"\n",
    "    oh_enc = OneHotEncoder()\n",
    "    oh_enc.fit(data[[\"Roof Material\"]])\n",
    "    ohe_cols = pd.DataFrame(oh_enc.transform(data[[\"Roof Material\"]]).todense(), \n",
    "                           columns = oh_enc.get_feature_names(),\n",
    "                           index = data.index)\n",
    "    return data.join(ohe_cols)\n",
    "    \n",
    "def ohe_wall_material(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material.  New columns are of the form 0x_QUALITY.\n",
    "    \"\"\"\n",
    "    oh_enc = OneHotEncoder()\n",
    "    oh_enc.fit(data[[\"Wall Material\"]])\n",
    "    ohe_cols = pd.DataFrame(oh_enc.transform(data[[\"Wall Material\"]]).todense(), \n",
    "                           columns = oh_enc.get_feature_names(),\n",
    "                           index = data.index)\n",
    "    return data.join(ohe_cols)\n",
    "\n",
    "def ohe_garage_1_material(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material.  New columns are of the form 0x_QUALITY.\n",
    "    \"\"\"\n",
    "    oh_enc = OneHotEncoder()\n",
    "    oh_enc.fit(data[[\"Garage 1 Material\"]])\n",
    "    ohe_cols = pd.DataFrame(oh_enc.transform(data[[\"Garage 1 Material\"]]).todense(), \n",
    "                           columns = oh_enc.get_feature_names(),\n",
    "                           index = data.index)\n",
    "    return data.join(ohe_cols)\n",
    "\n",
    "def ohe_garage_2_material(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material.  New columns are of the form 0x_QUALITY.\n",
    "    \"\"\"\n",
    "    oh_enc = OneHotEncoder()\n",
    "    oh_enc.fit(data[[\"Garage 2 Material\"]])\n",
    "    ohe_cols = pd.DataFrame(oh_enc.transform(data[[\"Garage 2 Material\"]]).todense(), \n",
    "                           columns = oh_enc.get_feature_names(),\n",
    "                           index = data.index)\n",
    "    return data.join(ohe_cols)\n",
    "def process_data_gm(data, pipeline_functions):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    for function, arguments, keyword_arguments in pipeline_functions:\n",
    "        if keyword_arguments and (not arguments):\n",
    "            data = data.pipe(function, **keyword_arguments)\n",
    "        elif (not keyword_arguments) and (arguments):\n",
    "            data = data.pipe(function, *arguments)\n",
    "        else:\n",
    "            data = data.pipe(function)\n",
    "#     X = data.drop(columns=[prediction_col]).to_numpy()\n",
    "#     y = data.loc[:, prediction_col].to_numpy()\n",
    "    return data\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "def logTransform(data, column):\n",
    "    df = data.copy()\n",
    "    df[\"Log \" + column] = np.log(data[column])\n",
    "    return df\n",
    "\n",
    "def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): the table to be filtered\n",
    "      variable (string): the column with numerical outliers\n",
    "      lower (numeric): observations with values lower than this will be removed\n",
    "      upper (numeric): observations with values higher than this will be removed\n",
    "    \n",
    "    Output:\n",
    "      a winsorized data frame with outliers removed\n",
    "      \n",
    "    Note: This function should not change mutate the contents of data.\n",
    "    \"\"\"  \n",
    "    return data[(data[variable] > lower) & (data[variable] < upper)]\n",
    "\n",
    "def rmse(predicted, actual):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      predicted (1D array): vector of predicted/fitted values\n",
    "      actual (1D array): vector of actual values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))\n",
    "\n",
    "def yearInterval(data):\n",
    "    data[\"Sale Year\"] = data[\"Sale Year\"] - 2013\n",
    "    return data\n",
    "\n",
    "def substitute_roof_material(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Roof Material' column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored 'Roof Material' column\n",
    "    \"\"\"\n",
    "    data[\"Roof Material\"] = data[\"Roof Material\"].replace({\n",
    "            1: \"Shingle/Asphalt\",\n",
    "            2: \"Tar&Gravel\",\n",
    "            3: \"Slate\",\n",
    "            4: \"Shake\",\n",
    "            5: \"Tile\",\n",
    "            6: \"Other\"})\n",
    "    return data\n",
    "def substitute_wall_material(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Roof Material' column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored 'Roof Material' column\n",
    "    \"\"\"\n",
    "    data[\"Wall Material\"] = data[\"Wall Material\"].replace({\n",
    "            1: \"Wood\",\n",
    "            2: \"Masonry\",\n",
    "            3: \"Wood&Masonry\",\n",
    "            4: \"Stucco\"})\n",
    "    return data\n",
    "def substitute_garage_1_material(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Roof Material' column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored 'Roof Material' column\n",
    "    \"\"\"\n",
    "    data[\"Garage 1 Material\"] = data[\"Garage 1 Material\"].replace({\n",
    "            1: \"Frame_1\",\n",
    "            2: \"Masonry_1\",\n",
    "            3: \"Frame/Masonry_1\",\n",
    "            4: \"Stucco_1\"})\n",
    "    return data\n",
    "def substitute_garage_1_material(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Roof Material' column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored 'Roof Material' column\n",
    "    \"\"\"\n",
    "    data[\"Garage 1 Material\"] = data[\"Garage 1 Material\"].replace({\n",
    "            0: \"Null_1\",\n",
    "            1: \"Frame_1\",\n",
    "            2: \"Masonry_1\",\n",
    "            3: \"Frame/Masonry_1\",\n",
    "            4: \"Stucco_1\"})\n",
    "    return data\n",
    "def substitute_garage_2_material(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Roof Material' column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored 'Roof Material' column\n",
    "    \"\"\"\n",
    "    data[\"Garage 2 Material\"] = data[\"Garage 2 Material\"].replace({\n",
    "            0: \"Null_2\",\n",
    "            1: \"Frame_2\",\n",
    "            2: \"Masonry_2\",\n",
    "            3: \"Frame/Masonry_2\",\n",
    "            4: \"Stucco_2\"})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8d9b0",
   "metadata": {},
   "source": [
    "## Step 2. Setup your `process_data_fm` function\n",
    "\n",
    "**Create your implementation of `process_data_fm` from into the following cell.**\n",
    "\n",
    "Here are a few additional things **you should check and change to make sure your `process_data_fm` function satisfies**:\n",
    "- Unlike part 1, we will not be expecting your `process_data_fm` function to return both the design matrix `X` and the observed target vector `y`; your function should now **only return X**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ee76e07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121997.35807673274]\n",
      "[121997.35807673274, 121381.75588147808]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "121689.5569791054"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please include all of your feature engineering process inside this function.\n",
    "# Do not modify the parameters of the function below. \n",
    "# Note that data will no longer have the column Sale Price in it directly, so plan your feature engineering process around that.\n",
    "def process_data_fm(data):\n",
    "    # Replace the following line with your own feature engineering pipeline\n",
    "    X = process_data_gm(data, [\n",
    "#         [remove_outliers, [\"Sale Price\", 499], None], \n",
    "#         [logTransform, [\"Sale Price\"], None],\n",
    "        [logTransform, [\"Building Square Feet\"], None],\n",
    "        [logTransform, [\"Property Class\"], None],\n",
    "        [add_total_bedrooms, None, None],\n",
    "        [substitute_roof_material, None, None],\n",
    "        [ohe_roof_material, None, None],\n",
    "        [substitute_wall_material, None, None],\n",
    "        [ohe_wall_material, None, None],\n",
    "        [yearInterval, None, None],\n",
    "#         [ohe_model_group, None, None],\n",
    "#         [substitute_garage_1_material, None, None],\n",
    "#         [ohe_garage_1_material, None, None],\n",
    "#         [substitute_garage_2_material, None, None],\n",
    "#         [ohe_garage_2_material, None, None],\n",
    "        [select_columns, [\"Bedrooms\", \"Log Building Square Feet\", \"Garage 1 Area\", \"Age\", \"Sale Year\", \n",
    "                          \"Sale Month of Year\", \"Most Recent Sale\", \"Neighborhood Code\",\n",
    "                         \"Town and Neighborhood\", \"Property Class\", \"x0_Shingle/Asphalt\",\n",
    "                         \"x0_Other\", \"x0_Stucco\", \"x0_Wood&Masonry\", \"x0_Masonry\",\n",
    "                         \"Basement\", \"Basement Finish\", \"Other Heating\", \"Central Air\", \"Fireplaces\",\n",
    "                         \"Attic Type\", \"Attic Finish\", \"Design Plan\", \"Cathedral Ceiling\",\n",
    "                         \"Garage 1 Size\", \"Garage 2 Size\", \"Garage 2 Attachment\",\n",
    "                          \"Garage 2 Material\", \"Apartments\",\n",
    "                         \"Garage 2 Area\", \"Porch\", \"Multi Code\", \"Number of Commercial Units\",\n",
    "                          \"Multi Property Indicator\", \"Use\", \"O'Hare Noise\", \"Floodplain\", \"Road Proximity\",\n",
    "                         \"Pure Market Filter\", \"Rooms\", \"Bathrooms\"], None]\n",
    "    ])\n",
    "#     print(X[\"x0_Shingle/Asphalt\"])\n",
    "    return X\n",
    "np.random.seed(100)\n",
    "coef = []\n",
    "inter = []\n",
    "models = {\"quant\": (process_data_fm, LinearRegression())}\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def cross_validate_rmse(phi_function, model):\n",
    "    model = clone(model)\n",
    "    five_fold = KFold(n_splits = 2, random_state = 100, shuffle = True)\n",
    "    rmse_values = []\n",
    "    for tr_ind, va_ind in five_fold.split(train_data):\n",
    "        \n",
    "        X_train = phi_function(train_data.iloc[tr_ind, :])\n",
    "        y_train = train_data['Sale Price'].iloc[tr_ind]\n",
    "        X_val = phi_function(train_data.iloc[va_ind, :])\n",
    "        y_val = train_data['Sale Price'].iloc[va_ind]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        rmse_values.append(rmse(y_val, model.predict(X_val)))\n",
    "        print(rmse_values)\n",
    "        \n",
    "    return np.mean(rmse_values)\n",
    "\n",
    "cross_validate_rmse(process_data_fm, LinearRegression())\n",
    "# for i in range(5):\n",
    "#     shuffled_indices = np.random.permutation(np.arange(len(train_data)))\n",
    "# #     print(shuffled_indices[0])\n",
    "#     new_data = train_data.iloc[shuffled_indices]\n",
    "#     y_train = np.log(new_data['Sale Price'])\n",
    "#     # train_data = train_data.drop(columns=['Sale Price'])\n",
    "#     X_train = process_data_fm(new_data)\n",
    "#     model.fit(X_train[:100000], y_train[:100000])\n",
    "#     y_fitted = model.predict(X_train)\n",
    "#     print(rmse(np.exp(y_fitted), np.exp(y_train)))\n",
    "#     coef.append(model.coef_)\n",
    "#     inter.append(model.intercept_)\n",
    "    \n",
    "# cross = []\n",
    "# for i in range(41):\n",
    "#     sum = 0\n",
    "#     for j in range(5):\n",
    "#         sum += coef[j][i]\n",
    "#     cross.append(sum/5)\n",
    "# y_fitted = []\n",
    "# y_train = np.log(train_data['Sale Price'])\n",
    "# X_train = process_data_fm(train_data)\n",
    "# print(X_train.T)\n",
    "# for i in range(len(train_data)):\n",
    "#     sum = coef[0]\n",
    "#     for j in range(41):\n",
    "#         print(j)\n",
    "#         sum += coef[j] * X_train.T.iloc[j]\n",
    "#     y_fitted.append(sum.flatten())\n",
    "# print(rmse(np.exp(y_fitted), np.exp(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "468d8ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SF'], dtype=object)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Modeling Group\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3e2d03",
   "metadata": {},
   "source": [
    "## Step 3. Train your model\n",
    "\n",
    "Run the following cell to import the new set of training data to fit your model on. **You can use any regression model, the following is just an example** If your `process_data_fm` satisfies all the specified requirements, the cell should run without any error.\n",
    "\n",
    "**As usual**, your model will predict the log-transformed sale price, and our grading will transform your predictions back to the normal vlaues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92caa085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('cook_county_contest_train.csv', index_col='Unnamed: 0')\n",
    "# train_data.index\n",
    "y_train = np.log(train_data['Sale Price'])\n",
    "# train_data = train_data.drop(columns=['Sale Price'])\n",
    "X_train = process_data_fm(train_data)\n",
    "model = lm.LinearRegression(fit_intercept=True)\n",
    "###You can use other models\n",
    "model.fit(X_train, y_train);\n",
    "# rmse(y_test_predicted, test_data[\"Sale Price\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e25eeeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135566.92616158223"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train = np.log(train_data['Sale Price'])\n",
    "# train_data = train_data.drop(columns=['Sale Price'])\n",
    "# X_train = process_data_fm(train_data)\n",
    "# model = lm.LinearRegression(fit_intercept=True)\n",
    "###You can use other models\n",
    "y_train = np.log(train_data['Sale Price'])\n",
    "# train_data = train_data.drop(columns=['Sale Price'])\n",
    "X_train = process_data_fm(train_data)\n",
    "model.fit(X_train, y_train)\n",
    "y_fitted = model.predict(X_train)\n",
    "rmse(np.exp(y_fitted), np.exp(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a0a31db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PIN', 'Property Class', 'Neighborhood Code', 'Land Square Feet',\n",
       "       'Town Code', 'Apartments', 'Wall Material', 'Roof Material', 'Basement',\n",
       "       'Basement Finish', 'Central Heating', 'Other Heating', 'Central Air',\n",
       "       'Fireplaces', 'Attic Type', 'Attic Finish', 'Design Plan',\n",
       "       'Cathedral Ceiling', 'Construction Quality', 'Site Desirability',\n",
       "       'Garage 1 Size', 'Garage 1 Material', 'Garage 1 Attachment',\n",
       "       'Garage 1 Area', 'Garage 2 Size', 'Garage 2 Material',\n",
       "       'Garage 2 Attachment', 'Garage 2 Area', 'Porch', 'Other Improvements',\n",
       "       'Building Square Feet', 'Repair Condition', 'Multi Code',\n",
       "       'Number of Commercial Units', 'Estimate (Land)', 'Estimate (Building)',\n",
       "       'Deed No.', 'Longitude', 'Latitude', 'Census Tract',\n",
       "       'Multi Property Indicator', 'Modeling Group', 'Age', 'Use',\n",
       "       'O'Hare Noise', 'Floodplain', 'Road Proximity', 'Sale Year',\n",
       "       'Sale Quarter', 'Sale Half-Year', 'Sale Quarter of Year',\n",
       "       'Sale Month of Year', 'Sale Half of Year', 'Most Recent Sale',\n",
       "       'Age Decade', 'Pure Market Filter', 'Garage Indicator',\n",
       "       'Neigborhood Code (mapping)', 'Town and Neighborhood', 'Description',\n",
       "       'Lot Size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ce6120",
   "metadata": {},
   "source": [
    "## Step 4. Make Predictions on the Test Dataset\n",
    "\n",
    "Run the following cell to estimate the sale price on the test dataset and export your model's predictions as a csv file called `predictions.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "436269dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sale Price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sale Price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12644/1971084010.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_data_fm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_test_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_predicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sale Price\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# predictions = pd.DataFrame({'Sale Price': y_test_predicted})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# predictions.to_csv('predictions.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sale Price'"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('cook_county_contest_test.csv', index_col='Unnamed: 0')\n",
    "X_test = process_data_fm(test_data)\n",
    "y_test_predicted = model.predict(X_test)\n",
    "# predictions = pd.DataFrame({'Sale Price': y_test_predicted})\n",
    "# predictions.to_csv('predictions.csv')\n",
    "# print('Your predictions have been exported as predictions.csv. Please download the file and submit it to Canvas. ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
